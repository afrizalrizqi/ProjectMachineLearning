# -*- coding: utf-8 -*-
"""Copy of cobaProjekML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U44HZJ5jaYp_GehbtDRJWOrftY4kQxFb

Import yang diperluin
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
import pandas as pd
import numpy as np
from zipfile import ZipFile
from pathlib import Path
import streamlit as st
import random, time

# Untuk visualisasi data
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px 

# %matplotlib inline
sns.set_palette('Set1')
sns.set()

# Untuk pemodelan
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Untuk menghilangkan warnings saat plotting seaborn
import warnings
warnings.filterwarnings('ignore')

"""Read File"""

rating = pd.read_csv('https://raw.githubusercontent.com/afrizalrizqi/ProjectMachineLearning/main/dataset/tourism_rating.csv')
place = pd.read_csv('https://raw.githubusercontent.com/afrizalrizqi/ProjectMachineLearning/main/dataset/tourism_with_id.csv')
user = pd.read_csv('https://raw.githubusercontent.com/afrizalrizqi/ProjectMachineLearning/main/dataset/user.csv')




"""DATA PREPROCESSING"""

all_data = np.concatenate((
    place.Place_Id.unique(),
    rating.Place_Id.unique()
))

all_data

all_data = np.sort(np.unique(all_data))
print(f"Total number of tourism: {len(all_data)}")

all_data_rating = rating
all_data_rating

all_data = pd.merge(all_data_rating, place[["Place_Id", "Place_Name","Description","City","Category","Rating","Price"]], on="Place_Id",how='left')
all_data

all_data['city_category'] = all_data[['City','Category']].agg(' '.join,axis=1)

all_data

preparation= all_data.drop_duplicates("Place_Id")
preparation

place_id = preparation.Place_Id.tolist()

place_name = preparation.Place_Name.tolist()

place_category = preparation.Category.tolist()

place_desc = preparation.Description.tolist()

place_city = preparation.City.tolist()

city_category = preparation.city_category.tolist()

price = preparation.Price.tolist()

place_rating = preparation.Rating.tolist()

data_baru = pd.DataFrame({
    "id":place_id,
    "name":place_name,
    "category":place_category,
    "description":place_desc,
    "city":place_city,
    "city_category":city_category,
    "price":price,
    "rating":place_rating
})

data_baru

top_10 = data_baru['id'].value_counts().reset_index()[0:10]
top_10 = pd.merge(top_10, preparation[['Place_Id','Place_Name']], how='left', left_on='index', right_on='Place_Id')

# Membuat visualisasi wisata dengan jumlah rating terbanyak
# plt.figure(figsize=(8,5))
# sns.barplot(x='Place_Id', y='Place_Name', data=top_10)
# plt.title('Jumlah Tempat Wisata dengan Rating Terbanyak', pad=20)
# plt.ylabel('Jumlah Rating')
# plt.xlabel('Nama Lokasi')
# plt.show()

# sns.countplot(y='Category', data=preparation)
# plt.title('Perbandingan Jumlah Kategori Wisata di Kota Bandung', pad=20)
# plt.show()

# plt.figure(figsize=(5,3))
# sns.boxplot(user['Age']);
# plt.title('Distribusi Usia User', pad=20)
# plt.show()

# plt.figure(figsize=(7,3))
# sns.boxplot(place['Price'])
# plt.title('Distribusi Harga Masuk Wisata', pad=20)
# plt.show()

# askot = user['Location'].apply(lambda x : x.split(',')[0])

# # Visualisasi asal kota dari user
# plt.figure(figsize=(8,6))
# sns.countplot(y=askot)
# plt.title('Jumlah Asal Kota dari User')
# plt.show()

"""Collaborative Filtering"""

import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

df = rating

user_ids = df.User_Id.unique().tolist()

user_to_user_encoded = {x:i for i, x in enumerate(user_ids)}

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

place_ids = df.Place_Id.unique().tolist()

place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}

place_encoded_to_place = {x: i for x, i in enumerate(place_ids)}

df['user'] = df.User_Id.map(user_to_user_encoded)

df['place'] = df.Place_Id.map(place_to_place_encoded)

num_users = len(user_to_user_encoded)

num_place = len(place_encoded_to_place)

df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

min_rating = min(df['Place_Ratings'])

max_rating= max(df['Place_Ratings'])

print('Number of User: {}, Number of Place: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_place, min_rating, max_rating
))

# """Train Test Split"""

# df = df.sample(frac=1,random_state=42)
# df

# x = df[['user','place']].values

# y = df['Place_Ratings'].apply(lambda x:(x-min_rating)/(max_rating-min_rating)).values

# train_indices = int(0.8 * df.shape[0])

# x_train,x_val,y_train,y_val = (
#     x[:train_indices],
#     x[train_indices:],
#     y[:train_indices],
#     y[train_indices:]
# )

# print(x,y)

"""Training"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_place, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_place = num_place
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.place_embedding = layers.Embedding(
        num_place,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.place_bias = layers.Embedding(num_place, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    place_vector = self.place_embedding(inputs[:, 1]) # memanggil layer embedding 3
    place_bias = self.place_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_place = tf.tensordot(user_vector, place_vector, 2)

    x = dot_user_place + user_bias + place_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_place, 100)

# model compile
# model.compile(
#     loss = tf.keras.losses.BinaryCrossentropy(),
#     optimizer = keras.optimizers.Adam(learning_rate=0.001),
#     metrics=[tf.keras.metrics.RootMeanSquaredError()]
# )

"""inisialisasi callback untuk jaga2 RMSE"""

# class myCallback(tf.keras.callbacks.Callback):
#   def on_epoch_end(self, epoch, logs={}):
#     if(logs.get('val_root_mean_squared_error')<0.25):
#       print('Metriks Validasi sudah sesuai harapan')
#       self.model.stop_training = True

# history = model.fit(
#     x = x_train,
#     y = y_train,
#     batch_size = 8,
#     epochs = 100,
#     validation_data = (x_val, y_val),
#     callbacks = [myCallback()]
# )

"""Recommendation"""

place_df = data_baru
df = pd.read_csv('https://raw.githubusercontent.com/afrizalrizqi/ProjectMachineLearning/main/dataset/tourism_rating.csv')

user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user['Place_Id'].values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

def recommend_destination(city, category, price):
    target_city = city
    target_category = category
    target_price_range = price   #rentang harga

    place_df_target_city_category_price = place_df[
        (place_df['city'] == target_city) &
        (place_df['category'] == target_category) &
        (place_df['price'].between(target_price_range[0], target_price_range[1]))
    ]

    # Gunakan logika yang sama untuk menyusun data untuk model
    place_not_visited_target_city_category_price = place_df_target_city_category_price[
        ~place_df_target_city_category_price['id'].isin(place_visited_by_user['Place_Id'].values)
    ]['id']

    place_not_visited_target_city_category_price = list(
        set(place_not_visited_target_city_category_price)
        .intersection(set(place_to_place_encoded.keys()))
    )

    place_not_visited_target_city_category_price = [[place_to_place_encoded.get(x)] for x in place_not_visited_target_city_category_price]
    user_place_array_target_city_category_price = np.hstack(
        ([[user_encoder]] * len(place_not_visited_target_city_category_price), place_not_visited_target_city_category_price)
    )

    # Check if the input data is non-empty
    if len(user_place_array_target_city_category_price) == 0:
        raise ValueError("Input data is empty. Please check the filtering logic.")
    else:
        ratings_target_city_category_price = model.predict(user_place_array_target_city_category_price).flatten()

    # Continue with the rest of your code
    top_ratings_indices_target_city_category_price = ratings_target_city_category_price.argsort()[-10:][::-1]
    recommended_place_ids_target_city_category_price = [
        place_encoded_to_place.get(place_not_visited_target_city_category_price[x][0]) for x in top_ratings_indices_target_city_category_price
    ]
    
    top_place_user_target_city_category_price = (
        place_visited_by_user.sort_values(
            by='Place_Ratings',
            ascending=False
        )
        .head(5)
        .Place_Id.values
    )

    recommended_place_target_city_category_price = place_df_target_city_category_price[
        place_df_target_city_category_price['id'].isin(recommended_place_ids_target_city_category_price)
    ]
    # pd.DataFrame(recommended_place_target_city_category_price)
    st.title("Top 10 Place Recommendation for You")
    
    # Ambil data dari DataFrame atau sumber data lainnya
    # df_sort = recommended_place_target_city_category_price.sort_values(by='rating', ascending=False)
    # recommended_places_data = recommended_place_target_city_category_price[['name', 'rating']]
    # recommended_places_data_sorted = df_sort[['name', 'rating']]

    # Menampilkan nama tempat dan rating
    # for index, row in recommended_places_data.iterrows():
    #     place = row['name']
    #     rating = row['rating']
    #     st.markdown(f"**Nama Tempat:** {place}  |  **Rating:** {rating}")

    
    # ## Membuat plot
    # st.bar_chart(recommended_places_data.set_index('name'))
    random.seed(time.time())
    random_state = random.randint(0, 999) 
    recommended_places_random = recommended_place_target_city_category_price.sample(frac=1, random_state=random_state)  # 'frac=1' untuk menampilkan semua baris, tetapi dalam urutan acak
    
    #Membuat tabel
    st.dataframe(recommended_places_random[['name', 'category', 'city', 'price', 'rating']])

    return recommended_places_random
